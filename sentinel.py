import os
import pandas as pd
import pyupbit
import requests  # [NEW] requests ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
from datetime import datetime

# --- Configuration ---
SYMBOL = "KRW-BTC"
DATA_DIR = "data/retraining_sets"
NTFY_TOPIC = "upbit-sentinel-alerts-a1b2c3d4" # [NEW] ntfy í† í”½ ì„¤ì •

def fetch_data():
    """
    ì§„ë‹¨ì„ ìœ„í•´ ì—…ë¹„íŠ¸ì—ì„œ 15ë¶„ë´‰ ë° 1ì‹œê°„ë´‰ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    """
    print("[INFO] Fetching recent market data from Upbit...")
    try:
        # 1. ë‹¨ê¸° ë¶„ì„ìš© 15ë¶„ë´‰ ë°ì´í„° (ì§€ë‚œ 24ì‹œê°„)
        df_15min = pyupbit.get_ohlcv(SYMBOL, interval="minute15", count=96) # 24 * 4
        # 2. ì¥ê¸° ì¶”ì„¸ ë¶„ì„ìš© 1ì‹œê°„ë´‰ ë°ì´í„° (ì§€ë‚œ 300ì‹œê°„)
        df_1h = pyupbit.get_ohlcv(SYMBOL, interval="minute60", count=300)
        
        if df_15min is None or df_1h is None:
            print("[ERROR] Failed to fetch data from Upbit.")
            return None, None
            
        print(f"[SUCCESS] Fetched {len(df_15min)} 15-min candles and {len(df_1h)} 1-hour candles.")
        return df_15min, df_1h
    except Exception as e:
        print(f"[ERROR] An exception occurred during data fetching: {e}")
        return None, None

def find_missed_opportunities(df_15min: pd.DataFrame, df_1h: pd.DataFrame):
    """
    "V-ì íšŒë³µ" íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ ë†“ì¹œ ê±°ë˜ ê¸°íšŒë¥¼ íƒì§€í•©ë‹ˆë‹¤.
    
    Returns:
        Tuple[pd.DataFrame, pd.Timestamp] | Tuple[None, None]: ê¸°íšŒ ë°ì´í„°ì™€ ì‹œì , ë˜ëŠ” None.
    """
    # --- 1. Macro Trend Check (1-hour data) ---
    df_1h['SMA_50'] = df_1h['close'].rolling(window=50).mean()
    df_1h['SMA_200'] = df_1h['close'].rolling(window=200).mean()
    
    if df_1h.iloc[-1]['SMA_50'] <= df_1h.iloc[-1]['SMA_200']:
        print("[INFO] Macro trend is not bullish. Sentinel is standing down.")
        return None, None
    
    print("[INFO] Macro trend is bullish. Scanning for V-Recovery patterns...")

    # --- 2. & 3. Dip and Recovery Check (15-min data) ---
    # ìµœê·¼ 6ì‹œê°„(24ë´‰)ì„ ê¸°ì¤€ìœ¼ë¡œ ê³ ì ì„ ì°¾ê³ , í•˜ë½ í›„ íšŒë³µí•˜ëŠ” íŒ¨í„´ì„ íƒì§€
    lookback_period = 24  # 6 hours
    recovery_period = 8   # 2 hours
    
    # ë’¤ì—ì„œë¶€í„° ìˆœíšŒí•˜ë©° íŒ¨í„´ì„ ì°¾ìŒ (ìµœì‹  ë°ì´í„°ë¥¼ ë¨¼ì € ë³´ë„ë¡)
    for i in range(len(df_15min) - recovery_period - 1, lookback_period, -1):
        
        # --- Identify a "Dip" ---
        recent_window = df_15min.iloc[i - lookback_period : i]
        peak_price = recent_window['high'].max()
        dip_candle = df_15min.iloc[i]
        
        if dip_candle['low'] <= peak_price * (1 - 0.015): # 1.5% ì´ìƒ í•˜ë½í•œ ì§€ì 
            
            # --- Identify a "Recovery" ---
            drop_amount = peak_price - dip_candle['low']
            recovery_target_price = dip_candle['low'] + (drop_amount * 0.5) # í•˜ë½ë¶„ì˜ 50% íšŒë³µ ëª©í‘œ
            
            recovery_window = df_15min.iloc[i + 1 : i + 1 + recovery_period]
            
            if recovery_window['high'].max() >= recovery_target_price:
                # V-íšŒë³µ ê¸°íšŒ í¬ì°© ì„±ê³µ!
                opportunity_start_index = recent_window['high'].idxmax()
                opportunity_end_index = recovery_window['high'].idxmax()
                opportunity_segment = df_15min.loc[opportunity_start_index : opportunity_end_index]
                
                return opportunity_segment, dip_candle.name # ê¸°íšŒ êµ¬ê°„ì˜ ë°ì´í„°ì™€, ë”¥ì´ ë°œìƒí•œ ì‹œì  ë°˜í™˜

    return None, None # ê¸°íšŒ ì—†ìŒ

def send_notification(opportunity_timestamp):
    """
    [REVISED] ë†“ì¹œ ê¸°íšŒì— ëŒ€í•œ ì•Œë¦¼ì„ ntfy.shë¥¼ í†µí•´ í‘¸ì‹œ ì•Œë¦¼ìœ¼ë¡œ ë³´ëƒ…ë‹ˆë‹¤.
    """
    title = "ğŸš¨ AI Commander: ë†“ì¹œ ê±°ë˜ ê¸°íšŒ í¬ì°©!"
    message = f"V-íšŒë³µ íŒ¨í„´ì´ {opportunity_timestamp} ê²½ì— ë°œìƒí–ˆìœ¼ë‚˜, ì—ì´ì „íŠ¸ê°€ ì§„ì…í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¬í›ˆë ¨ì„ ìœ„í•´ í•´ë‹¹ ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."
    
    try:
        requests.post(
            f"https://ntfy.sh/{NTFY_TOPIC}",
            data=message.encode('utf-8'),
            headers={
                "Title": title.encode('utf-8'),
                "Priority": "high", # ê¸´ê¸‰ ì•Œë¦¼
                "Tags": "warning"    # ê²½ê³  ì•„ì´ì½˜
            }
        )
        print(f"[INFO] Notification sent successfully to ntfy topic: {NTFY_TOPIC}")
    except Exception as e:
        print(f"[ERROR] Failed to send ntfy notification: {e}")

    # ì½˜ì†”ì—ë„ ë¡œê·¸ë¥¼ ë‚¨ê¹ë‹ˆë‹¤.
    print("\n" + "="*60)
    print(f"[!!] {title}")
    print(message)
    print("="*60 + "\n")

def trigger_retraining_pipeline(data_segment: pd.DataFrame, timestamp: pd.Timestamp):
    """
    ë†“ì¹œ ê¸°íšŒ ë°ì´í„°ë¥¼ ì €ì¥í•˜ì—¬ ì¬í›ˆë ¨ íŒŒì´í”„ë¼ì¸ì„ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.
    """
    print("[INFO] Initializing automated retraining pipeline...")
    try:
        os.makedirs(DATA_DIR, exist_ok=True)
        filename = f"missed_opportunity_{timestamp.strftime('%Y%m%d_%H%M%S')}.csv"
        filepath = os.path.join(DATA_DIR, filename)
        data_segment.to_csv(filepath)
        
        print(f"[SUCCESS] Saved data for retraining to: {filepath}")
        print("The agent will learn from this in the next training cycle.")
    except Exception as e:
        print(f"[ERROR] Failed to save retraining data: {e}")

def main():
    """
    ìŠ¤í¬ë¦½íŠ¸ì˜ ë©”ì¸ ì‹¤í–‰ ë¡œì§
    """
    df_15min, df_1h = fetch_data()
    
    if df_15min is None or df_1h is None:
        return

    opportunity_segment, opportunity_timestamp = find_missed_opportunities(df_15min, df_1h)
    
    if opportunity_segment is not None:
        send_notification(opportunity_timestamp)
        trigger_retraining_pipeline(opportunity_segment, opportunity_timestamp)
    else:
        print(f"[OK] No missed opportunities detected in the last 24 hours. ({datetime.now().strftime('%Y-%m-%d %H:%M')})")

if __name__ == '__main__':
    main()